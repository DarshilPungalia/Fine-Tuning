{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf7d1a1",
      "metadata": {
        "id": "2bf7d1a1"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import RecursiveUrlLoader, WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_transformers import BeautifulSoupTransformer\n",
        "import pickle\n",
        "import unicodedata\n",
        "import re\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "cTXr_4EOvaet",
      "metadata": {
        "id": "cTXr_4EOvaet"
      },
      "outputs": [],
      "source": [
        "def bs4_extractor(html: str) -> str:\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    return soup.get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "972dfa04",
      "metadata": {
        "id": "972dfa04"
      },
      "outputs": [],
      "source": [
        "loader  = RecursiveUrlLoader('https://python.langchain.com/api_reference/',\n",
        "                             max_depth=12,\n",
        "                             extractor=bs4_extractor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "bc4fcdb3",
      "metadata": {
        "id": "bc4fcdb3"
      },
      "outputs": [],
      "source": [
        "page = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "ac11501e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac11501e",
        "outputId": "7f40c5d6-3bf7-4e98-84aa-768dbf11d088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5339"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "f9OHb-pswbpG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9OHb-pswbpG",
        "outputId": "1f9bf219-3651-4d17-d8dd-d1ec87b29557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 https://python.langchain.com/api_reference/\n",
            "1 https://python.langchain.com/api_reference/ibm/index.html\n",
            "2 https://python.langchain.com/api_reference/exa/index.html\n",
            "3 https://python.langchain.com/api_reference/nomic/index.html\n",
            "4 https://python.langchain.com/api_reference/index.html\n",
            "5 https://python.langchain.com/api_reference/weaviate/index.html\n",
            "6 https://python.langchain.com/api_reference/_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf\n",
            "7 https://python.langchain.com/api_reference/_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf\n",
            "8 https://python.langchain.com/api_reference/standard_tests/index.html\n",
            "9 https://python.langchain.com/api_reference/search.html\n",
            "10 https://python.langchain.com/api_reference/google_community/index.html\n",
            "11 https://python.langchain.com/api_reference/milvus/index.html\n",
            "12 https://python.langchain.com/api_reference/_static/pygments.css?v=8f2a1f02\n",
            "13 https://python.langchain.com/api_reference/neo4j/index.html\n",
            "14 https://python.langchain.com/api_reference/azure_dynamic_sessions/index.html\n",
            "15 https://python.langchain.com/api_reference/langchain/index.html\n",
            "16 https://python.langchain.com/api_reference/groq/index.html\n",
            "17 https://python.langchain.com/api_reference/anthropic/index.html\n",
            "18 https://python.langchain.com/api_reference/snowflake/index.html\n",
            "19 https://python.langchain.com/api_reference/_static/styles/theme.css?digest=8878045cc6db502f8baf\n",
            "20 https://python.langchain.com/api_reference/aws/index.html\n",
            "21 https://python.langchain.com/api_reference/text_splitters/index.html\n",
            "22 https://python.langchain.com/api_reference/neo4j/vectorstores/langchain_neo4j.vectorstores.neo4j_vector.remove_lucene_chars.html\n",
            "23 https://python.langchain.com/api_reference/redis/index.html\n",
            "24 https://python.langchain.com/api_reference/chroma/index.html\n",
            "25 https://python.langchain.com/api_reference/community/index.html\n",
            "26 https://python.langchain.com/api_reference/azure_ai/index.html\n",
            "27 https://python.langchain.com/api_reference/xai/index.html\n",
            "28 https://python.langchain.com/api_reference/core/index.html\n",
            "29 https://python.langchain.com/api_reference/huggingface/index.html\n",
            "30 https://python.langchain.com/api_reference/ai21/index.html\n",
            "31 https://python.langchain.com/api_reference/ollama/index.html\n",
            "32 https://python.langchain.com/api_reference/sqlserver/index.html\n",
            "33 https://python.langchain.com/api_reference/pinecone/index.html\n",
            "34 https://python.langchain.com/api_reference/nvidia_ai_endpoints/index.html\n",
            "35 https://python.langchain.com/api_reference/mistralai/index.html\n",
            "36 https://python.langchain.com/api_reference/google_vertexai/index.html\n",
            "37 https://python.langchain.com/api_reference/nomic/embeddings.html\n",
            "38 https://python.langchain.com/api_reference/prompty/index.html\n",
            "39 https://python.langchain.com/api_reference/unstructured/index.html\n",
            "40 https://python.langchain.com/api_reference/voyageai/index.html\n",
            "41 https://python.langchain.com/api_reference/nomic/embeddings/langchain_nomic.embeddings.NomicEmbeddings.html\n",
            "42 https://python.langchain.com/api_reference/mongodb/index.html\n",
            "43 https://python.langchain.com/api_reference/astradb/index.html\n",
            "44 https://python.langchain.com/api_reference/upstage/index.html\n",
            "45 https://python.langchain.com/api_reference/deepseek/index.html\n",
            "46 https://python.langchain.com/api_reference/cerebras/index.html\n",
            "47 https://python.langchain.com/api_reference/perplexity/index.html\n",
            "48 https://python.langchain.com/api_reference/tavily/index.html\n",
            "49 https://python.langchain.com/api_reference/sema4/index.html\n",
            "50 https://python.langchain.com/api_reference/reference.html\n",
            "51 https://python.langchain.com/api_reference/_static/css/custom.css?v=8e9fa5b3\n",
            "52 https://python.langchain.com/api_reference/_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf\n",
            "53 https://python.langchain.com/api_reference/postgres/index.html\n",
            "54 https://python.langchain.com/api_reference/google_genai/index.html\n",
            "55 https://python.langchain.com/api_reference/cohere/index.html\n",
            "56 https://python.langchain.com/api_reference/_static/copybutton.css?v=76b2166b\n",
            "57 https://python.langchain.com/api_reference/openai/index.html\n",
            "58 https://python.langchain.com/api_reference/qdrant/index.html\n",
            "59 https://python.langchain.com/api_reference/fireworks/index.html\n",
            "60 https://python.langchain.com/api_reference/_static/sphinx-design.min.css?v=95c83b7e\n",
            "61 https://python.langchain.com/api_reference/elasticsearch/index.html\n",
            "62 https://python.langchain.com/api_reference/together/index.html\n",
            "63 https://python.langchain.com/api_reference/experimental/index.html\n",
            "64 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.SparseVectorStrategy.html\n",
            "65 https://python.langchain.com/api_reference/elasticsearch/cache.html\n",
            "66 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.DenseVectorStrategy.html\n",
            "67 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.AsyncRetrievalStrategy.html\n",
            "68 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.BM25Strategy.html\n",
            "69 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.RetrievalStrategy.html\n",
            "70 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.DenseVectorScriptScoreStrategy.html\n",
            "71 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.ElasticsearchStore.html\n",
            "72 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.AsyncSparseVectorStrategy.html\n",
            "73 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.AsyncDenseVectorStrategy.html\n",
            "74 https://python.langchain.com/api_reference/elasticsearch/chat_history.html\n",
            "75 https://python.langchain.com/api_reference/elasticsearch/retrievers.html\n",
            "76 https://python.langchain.com/api_reference/elasticsearch/vectorstores.html\n",
            "77 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.AsyncDenseVectorScriptScoreStrategy.html\n",
            "78 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.AsyncBM25Strategy.html\n",
            "79 https://python.langchain.com/api_reference/elasticsearch/client.html\n",
            "80 https://python.langchain.com/api_reference/_modules/langchain_elasticsearch/vectorstores.html\n",
            "81 https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.AsyncElasticsearchStore.html\n",
            "82 https://python.langchain.com/api_reference/_modules/elasticsearch/helpers/vectorstore/_sync/strategies.html\n",
            "83 https://python.langchain.com/api_reference/elasticsearch/embeddings.html\n",
            "84 https://python.langchain.com/api_reference/exa/tools.html\n",
            "85 https://python.langchain.com/api_reference/exa/tools/langchain_exa.tools.ExaFindSimilarResults.html\n",
            "86 https://python.langchain.com/api_reference/exa/retrievers.html\n",
            "87 https://python.langchain.com/api_reference/exa/retrievers/langchain_exa.retrievers.ExaSearchRetriever.html\n",
            "88 https://python.langchain.com/api_reference/exa/tools/langchain_exa.tools.ExaSearchResults.html\n",
            "89 https://python.langchain.com/api_reference/ibm/llms.html\n",
            "90 https://python.langchain.com/api_reference/ibm/utils.html\n",
            "91 https://python.langchain.com/api_reference/ibm/utils/langchain_ibm.utils.check_duplicate_chat_params.html\n",
            "92 https://python.langchain.com/api_reference/ibm/utils/langchain_ibm.utils.extract_chat_params.html\n",
            "93 https://python.langchain.com/api_reference/ibm/chat_models.html\n",
            "94 https://python.langchain.com/api_reference/ibm/utils/langchain_ibm.utils.check_for_attribute.html\n",
            "95 https://python.langchain.com/api_reference/ibm/toolkit.html\n",
            "96 https://python.langchain.com/api_reference/ibm/utils/langchain_ibm.utils.convert_to_watsonx_tool.html\n",
            "97 https://python.langchain.com/api_reference/ibm/rerank.html\n",
            "98 https://python.langchain.com/api_reference/ibm/toolkit/langchain_ibm.toolkit.WatsonxToolkit.html\n",
            "99 https://python.langchain.com/api_reference/ibm/embeddings.html\n",
            "100 https://python.langchain.com/api_reference/ibm/utils/langchain_ibm.utils.extract_params.html\n",
            "101 https://python.langchain.com/api_reference/ibm/llms/langchain_ibm.llms.WatsonxLLM.html\n",
            "102 https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html\n",
            "103 https://python.langchain.com/api_reference/core/caches/langchain_core.caches.BaseCache.html\n",
            "104 https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html\n",
            "105 https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableSerializable.html\n",
            "106 https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html\n",
            "107 https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html\n",
            "108 https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.utils.ConfigurableFieldMultiOption.html\n",
            "109 https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.utils.ConfigurableFieldSingleOption.html\n",
            "110 https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackManager.html\n",
            "111 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.BaseLLM.html\n",
            "112 https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.utils.ConfigurableField.html\n",
            "113 https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.retry.ExponentialJitterParams.html\n",
            "114 https://python.langchain.com/api_reference/_modules/langchain_ibm/llms.html\n",
            "115 https://python.langchain.com/api_reference/core/prompt_values/langchain_core.prompt_values.PromptValue.html\n",
            "116 https://python.langchain.com/api_reference/ibm/embeddings/langchain_ibm.embeddings.WatsonxEmbeddings.html\n",
            "117 https://python.langchain.com/api_reference/core/embeddings/langchain_core.embeddings.embeddings.Embeddings.html\n",
            "118 https://python.langchain.com/api_reference/_modules/langchain_ibm/embeddings.html\n",
            "119 https://python.langchain.com/api_reference/ibm/chat_models/langchain_ibm.chat_models.ChatWatsonx.html\n",
            "120 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.BaseTool.html\n",
            "121 https://python.langchain.com/api_reference/core/tracers.html\n",
            "122 https://python.langchain.com/api_reference/core/outputs.html\n",
            "123 https://python.langchain.com/api_reference/core/documents.html\n",
            "124 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.get_all_basemodel_annotations.html\n",
            "125 https://python.langchain.com/api_reference/core/example_selectors.html\n",
            "126 https://python.langchain.com/api_reference/core/caches.html\n",
            "127 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html\n",
            "128 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.ToolException.html\n",
            "129 https://python.langchain.com/api_reference/core/sys_info.html\n",
            "130 https://python.langchain.com/api_reference/core/prompt_values.html\n",
            "131 https://python.langchain.com/api_reference/core/retrievers.html\n",
            "132 https://python.langchain.com/api_reference/core/runnables.html\n",
            "133 https://python.langchain.com/api_reference/core/output_parsers.html\n",
            "134 https://python.langchain.com/api_reference/core/chat_loaders.html\n",
            "135 https://python.langchain.com/api_reference/core/agents.html\n",
            "136 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.SchemaAnnotationError.html\n",
            "137 https://python.langchain.com/api_reference/core/language_models.html\n",
            "138 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.simple.Tool.html\n",
            "139 https://python.langchain.com/api_reference/core/chat_sessions.html\n",
            "140 https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolCall.html\n",
            "141 https://python.langchain.com/api_reference/core/vectorstores.html\n",
            "142 https://python.langchain.com/api_reference/core/stores.html\n",
            "143 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.create_schema_from_function.html\n",
            "144 https://python.langchain.com/api_reference/core/globals.html\n",
            "145 https://python.langchain.com/api_reference/core/document_loaders.html\n",
            "146 https://python.langchain.com/api_reference/core/load.html\n",
            "147 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.structured.StructuredTool.html\n",
            "148 https://python.langchain.com/api_reference/core/tools.html\n",
            "149 https://python.langchain.com/api_reference/core/embeddings.html\n",
            "150 https://python.langchain.com/api_reference/core/callbacks.html\n",
            "151 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.BaseToolkit.html\n",
            "152 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.convert_runnable_to_tool.html\n",
            "153 https://python.langchain.com/api_reference/core/chat_history.html\n",
            "154 https://python.langchain.com/api_reference/_modules/langchain_core/tools/base.html\n",
            "155 https://python.langchain.com/api_reference/core/indexing.html\n",
            "156 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.retriever.RetrieverInput.html\n",
            "157 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.render.render_text_description.html\n",
            "158 https://python.langchain.com/api_reference/core/utils.html\n",
            "159 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.retriever.create_retriever_tool.html\n",
            "160 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.render.render_text_description_and_args.html\n",
            "161 https://python.langchain.com/api_reference/core/exceptions.html\n",
            "162 https://python.langchain.com/api_reference/core/rate_limiters.html\n",
            "163 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.InjectedToolArg.html\n",
            "164 https://python.langchain.com/api_reference/core/structured_query.html\n",
            "165 https://python.langchain.com/api_reference/core/messages.html\n",
            "166 https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.InjectedToolCallId.html\n",
            "167 https://python.langchain.com/api_reference/core/beta.html\n",
            "168 https://python.langchain.com/api_reference/core/prompts.html\n",
            "169 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html\n",
            "170 https://python.langchain.com/api_reference/core/utils/langchain_core.utils.function_calling.convert_to_openai_tool.html\n",
            "171 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.GenericFakeChatModel.html\n",
            "172 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.aupdate_cache.html\n",
            "173 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake.FakeStreamingListLLM.html\n",
            "174 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.SimpleChatModel.html\n",
            "175 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.FakeMessagesListChatModel.html\n",
            "176 https://python.langchain.com/api_reference/experimental/video_captioning/langchain_experimental.video_captioning.models.BaseModel.html\n",
            "177 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.create_base_retry_decorator.html\n",
            "178 https://python.langchain.com/api_reference/_modules/langchain_core/language_models/chat_models.html\n",
            "179 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake.FakeListLLMError.html\n",
            "180 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.LLM.html\n",
            "181 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.FakeListChatModel.html\n",
            "182 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.update_cache.html\n",
            "183 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.generate_from_stream.html\n",
            "184 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.base.LangSmithParams.html\n",
            "185 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.aget_prompts.html\n",
            "186 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake.FakeListLLM.html\n",
            "187 https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessageChunk.html\n",
            "188 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.base.BaseLanguageModel.html\n",
            "189 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.ParrotFakeChatModel.html\n",
            "190 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.get_prompts.html\n",
            "191 https://python.langchain.com/api_reference/core/rate_limiters/langchain_core.rate_limiters.BaseRateLimiter.html\n",
            "192 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.FakeChatModel.html\n",
            "193 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.FakeListChatModelError.html\n",
            "194 https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.agenerate_from_stream.html\n",
            "195 https://python.langchain.com/api_reference/_modules/langchain_ibm/chat_models.html\n",
            "196 https://python.langchain.com/api_reference/_modules/index.html\n",
            "197 https://python.langchain.com/api_reference/ibm/rerank/langchain_ibm.rerank.WatsonxRerank.html\n",
            "198 https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html\n",
            "199 https://python.langchain.com/api_reference/core/documents/langchain_core.documents.transformers.BaseDocumentTransformer.html\n",
            "200 https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Blob.html\n",
            "201 https://python.langchain.com/api_reference/core/documents/langchain_core.documents.compressor.BaseDocumentCompressor.html\n",
            "202 https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.BaseMedia.html\n",
            "203 https://python.langchain.com/api_reference/_modules/langchain_core/documents/base.html\n",
            "204 https://python.langchain.com/api_reference/_modules/langchain_ibm/rerank.html\n",
            "205 https://python.langchain.com/api_reference/ibm/toolkit/langchain_ibm.toolkit.WatsonxTool.html\n",
            "206 https://python.langchain.com/api_reference/_modules/langchain_ibm/toolkit.html\n",
            "207 https://python.langchain.com/api_reference/huggingface/utils/langchain_huggingface.utils.import_utils.is_optimum_version.html\n",
            "208 https://python.langchain.com/api_reference/huggingface/embeddings.html\n",
            "209 https://python.langchain.com/api_reference/huggingface/embeddings/langchain_huggingface.embeddings.huggingface_endpoint.HuggingFaceEndpointEmbeddings.html\n",
            "210 https://python.langchain.com/api_reference/huggingface/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html\n",
            "211 https://python.langchain.com/api_reference/huggingface/utils.html\n",
            "212 https://python.langchain.com/api_reference/huggingface/chat_models.html\n",
            "213 https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.TGI_RESPONSE.html\n",
            "214 https://python.langchain.com/api_reference/huggingface/llms.html\n",
            "215 https://python.langchain.com/api_reference/huggingface/utils/langchain_huggingface.utils.import_utils.is_optimum_intel_available.html\n",
            "216 https://python.langchain.com/api_reference/huggingface/utils/langchain_huggingface.utils.import_utils.compare_versions.html\n",
            "217 https://python.langchain.com/api_reference/huggingface/utils/langchain_huggingface.utils.import_utils.is_openvino_available.html\n",
            "218 https://python.langchain.com/api_reference/huggingface/utils/langchain_huggingface.utils.import_utils.is_optimum_available.html\n",
            "219 https://python.langchain.com/api_reference/_modules/langchain_huggingface/utils/import_utils.html\n",
            "220 https://python.langchain.com/api_reference/huggingface/utils/langchain_huggingface.utils.import_utils.is_ipex_available.html\n",
            "221 https://python.langchain.com/api_reference/huggingface/utils/langchain_huggingface.utils.import_utils.is_optimum_intel_version.html\n"
          ]
        }
      ],
      "source": [
        "for i, j in enumerate(page):\n",
        "    print(i, j.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ffab1b",
      "metadata": {
        "id": "14ffab1b"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.encode('latin1', errors='ignore').decode('utf-8', errors='ignore')\n",
        "\n",
        "    text = unicodedata.normalize('NFKC', text)\n",
        "\n",
        "    text = ''.join(c for c in text if unicodedata.category(c)[0] != 'C')\n",
        "    text = re.sub(r\"LangChain\\s+documentation$\", \"\", text).strip()\n",
        "    text = text.split(\"|\")[0].strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "b402cde1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b402cde1",
        "outputId": "352bf20f-6e89-4313-d3e5-959751528b1b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'langchain-fireworks: 0.3.0'"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text('langchain-fireworks: 0.3.0 √¢‚Ç¨‚Äù √∞≈∏¬¶≈ì√∞≈∏‚Äù‚Äî LangChain  documentation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "QHkyjPn_8dUC",
      "metadata": {
        "id": "QHkyjPn_8dUC"
      },
      "outputs": [],
      "source": [
        "def remove_blank_lines(text):\n",
        "    lines = text.splitlines()\n",
        "    while lines and lines[0].strip() == \"\":\n",
        "        lines.pop(0)\n",
        "    while lines and lines[-1].strip() == \"\":\n",
        "        lines.pop()\n",
        "    return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "f-3iy8-E8AbR",
      "metadata": {
        "id": "f-3iy8-E8AbR"
      },
      "outputs": [],
      "source": [
        "def extract_main_content(text, marker_leading=\"LangChain Python API Reference\", marker_trailing=\"¬© Copyright 2025, LangChain Inc.\"):\n",
        "    main_content = text.split(marker_leading, 1)[-1]\n",
        "    main_content = main_content.split(marker_trailing, 1)[0]\n",
        "    main_content = main_content.strip()\n",
        "    main_content = remove_blank_lines(main_content)\n",
        "    return main_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "zqrtB6yr8gtp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqrtB6yr8gtp",
        "outputId": "a69e7d2e-d830-4a57-cbea-daca213aee40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After:\n",
            "'langchain: 0.3.25\\nrunnables\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nrunnables#\\nLangChain Runnable and the LangChain Expression Language (LCEL).\\nThe LangChain Expression Language (LCEL) offers a declarative method to build\\nproduction-grade programs that harness the power of LLMs.\\nPrograms created using LCEL and LangChain Runnables inherently support\\nsynchronous, asynchronous, batch, and streaming operations.\\nSupport for async allows servers hosting the LCEL based programs\\nto scale better for higher concurrent loads.\\nBatch operations allow for processing multiple inputs in parallel.\\nStreaming of intermediate outputs, as they‚Äôre being generated, allows for\\ncreating more responsive UX.\\nThis module contains non-core Runnable classes.\\nClasses\\n\\n\\nrunnables.hub.HubRunnable\\nAn instance of a runnable stored in the LangChain Hub.\\n\\nrunnables.openai_functions.OpenAIFunction\\nA function description for ChatOpenAI\\n\\nrunnables.openai_functions.OpenAIFunctionsRouter\\nA runnable that routes to the selected function.'\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "runnables ‚Äî ü¶úüîó LangChain  documentation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Skip to main content\n",
        "\n",
        "\n",
        "Back to top\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Ctrl+K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Reference\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Ctrl+K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Docs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "GitHub\n",
        "\n",
        "\n",
        "\n",
        "X / Twitter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Ctrl+K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Reference\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Docs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "GitHub\n",
        "\n",
        "\n",
        "\n",
        "X / Twitter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Section Navigation\n",
        "Base packages\n",
        "\n",
        "Core\n",
        "Langchain\n",
        "agents\n",
        "callbacks\n",
        "chains\n",
        "chat_models\n",
        "embeddings\n",
        "evaluation\n",
        "globals\n",
        "hub\n",
        "indexes\n",
        "memory\n",
        "model_laboratory\n",
        "output_parsers\n",
        "retrievers\n",
        "runnables\n",
        "HubRunnable\n",
        "OpenAIFunction\n",
        "OpenAIFunctionsRouter\n",
        "\n",
        "\n",
        "smith\n",
        "storage\n",
        "\n",
        "\n",
        "Text Splitters\n",
        "Community\n",
        "Experimental\n",
        "\n",
        "Integrations\n",
        "\n",
        "AI21\n",
        "Anthropic\n",
        "AstraDB\n",
        "AWS\n",
        "Azure Ai\n",
        "Azure Dynamic Sessions\n",
        "Cerebras\n",
        "Chroma\n",
        "Cohere\n",
        "Deepseek\n",
        "Elasticsearch\n",
        "Exa\n",
        "Fireworks\n",
        "Google Community\n",
        "Google GenAI\n",
        "Google VertexAI\n",
        "Groq\n",
        "Huggingface\n",
        "IBM\n",
        "Milvus\n",
        "MistralAI\n",
        "MongoDB\n",
        "Neo4J\n",
        "Nomic\n",
        "Nvidia Ai Endpoints\n",
        "Ollama\n",
        "OpenAI\n",
        "Perplexity\n",
        "Pinecone\n",
        "Postgres\n",
        "Prompty\n",
        "Qdrant\n",
        "Redis\n",
        "Sema4\n",
        "Snowflake\n",
        "Sqlserver\n",
        "Standard Tests\n",
        "Tavily\n",
        "Together\n",
        "Unstructured\n",
        "Upstage\n",
        "VoyageAI\n",
        "Weaviate\n",
        "XAI\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "LangChain Python API Reference\n",
        "langchain: 0.3.25\n",
        "runnables\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "runnables#\n",
        "LangChain Runnable and the LangChain Expression Language (LCEL).\n",
        "The LangChain Expression Language (LCEL) offers a declarative method to build\n",
        "production-grade programs that harness the power of LLMs.\n",
        "Programs created using LCEL and LangChain Runnables inherently support\n",
        "synchronous, asynchronous, batch, and streaming operations.\n",
        "Support for async allows servers hosting the LCEL based programs\n",
        "to scale better for higher concurrent loads.\n",
        "Batch operations allow for processing multiple inputs in parallel.\n",
        "Streaming of intermediate outputs, as they‚Äôre being generated, allows for\n",
        "creating more responsive UX.\n",
        "This module contains non-core Runnable classes.\n",
        "Classes\n",
        "\n",
        "\n",
        "runnables.hub.HubRunnable\n",
        "An instance of a runnable stored in the LangChain Hub.\n",
        "\n",
        "runnables.openai_functions.OpenAIFunction\n",
        "A function description for ChatOpenAI\n",
        "\n",
        "runnables.openai_functions.OpenAIFunctionsRouter\n",
        "A runnable that routes to the selected function.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      ¬© Copyright 2025, LangChain Inc.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cleaned = extract_main_content(text)\n",
        "\n",
        "print(f\"After:\\n{cleaned!r}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef6364c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef6364c3",
        "outputId": "d29e3798-744b-45ed-d16a-e134252eef61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5339/5339 [00:00<00:00, 8196.88it/s]\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "documentation = {}\n",
        "\n",
        "for count, document in enumerate(tqdm(page, desc=\"Processing documents\")):\n",
        "    metadata = document.metadata\n",
        "    content = document.page_content\n",
        "\n",
        "    if 'source' in metadata and not content.strip():\n",
        "        continue\n",
        "\n",
        "    if 'title' in metadata:\n",
        "        name = clean_text(metadata['title'])\n",
        "    else:\n",
        "        url = metadata.get('source', '')\n",
        "        name = url.rstrip('/').split('/')[-1] or f\"doc_{count}\"\n",
        "\n",
        "    name = name.strip().lower().replace(\" \", \"_\")\n",
        "\n",
        "    trimmed = extract_main_content(content)\n",
        "\n",
        "    documentation[name] = trimmed\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "d02f8899",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d02f8899",
        "outputId": "acd5e7c4-6fc7-4231-a297-20584c19e341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "langchain_python_api_reference\n",
            "langchain-ibm:_0.3.11\n",
            "langchain-exa:_0.2.1\n",
            "langchain-nomic:_0.1.4\n",
            "langchain-weaviate:_0.0.4\n",
            "pydata-sphinx-theme.js?digest=8878045cc6db502f8baf\n",
            "pydata-sphinx-theme.css?digest=8878045cc6db502f8baf\n",
            "langchain-tests:_0.3.19\n",
            "search_-\n",
            "langchain-google-community:_2.0.7\n",
            "search\n",
            "google_speech_to_text\n",
            "pygments.css?v=8f2a1f02\n",
            "langchain-neo4j:_0.4.0\n",
            "langchain-groq:_0.3.2\n",
            "langchain-anthropic:_0.3.13\n",
            "langchain-redis:_0.2.1\n",
            "vertex_ai_search\n",
            "documentai_warehouse\n",
            "gmail\n",
            "langchain-huggingface:_0.2.0\n",
            "langchain-ai21:_1.1.0\n",
            "langchain-mistralai:_0.2.10\n",
            "googlesearchrun\n",
            "langchain-upstage:_0.6.0\n",
            "custom.css?v=8e9fa5b3\n",
            "langchain-elasticsearch:_0.3.2\n",
            "bq_storage_vectorstores\n",
            "langchain-azure-dynamic-sessions:_0.2.0\n",
            "langchain:_0.3.25\n",
            "langchain-chroma:_0.2.4\n",
            "langchain-community:_0.3.24\n",
            "langchain-xai:_0.2.3\n",
            "langchain-ollama:_0.3.3\n",
            "langchain-sqlserver:_0.1.2\n",
            "vertex_check_grounding\n",
            "drive\n",
            "langchain-prompty:_0.1.1\n",
            "langchain-unstructured:_0.1.6\n",
            "calendar\n",
            "langchain-voyageai:_0.1.4\n",
            "langchain-astradb:_0.6.0\n",
            "langchain-deepseek:_0.1.3\n",
            "geocoding\n",
            "vertex_rank\n",
            "langchain-cerebras:_0.5.0\n",
            "bootstrap.js?digest=8878045cc6db502f8baf\n",
            "copybutton.css?v=76b2166b\n",
            "langchain-qdrant:_0.2.0\n",
            "sphinx-design.min.css?v=95c83b7e\n",
            "langchain-mongodb:_0.6.2___langchain_mongodb__documentation\n",
            "langchain-milvus:_0.2.0rc1\n",
            "bigquery\n",
            "googlesearchresults\n",
            "langchain-azure-ai:_0.1.2\n",
            "langchain-pinecone:_0.2.6\n",
            "langchain-openai:_0.3.17\n",
            "langchain-text-splitters:_0.3.8\n",
            "langchain-experimental:_0.3.5rc1\n",
            "docai\n",
            "translate\n",
            "gcs_directory\n",
            "places_api\n",
            "vision\n",
            "langchain-snowflake:_0.1.3\n",
            "theme.css?digest=8878045cc6db502f8baf\n",
            "langchain-aws:_0.2.23\n",
            "googleplacestool\n",
            "langchain-core:_0.3.60\n",
            "langchain-nvidia-ai-endpoints:_0.3.10\n",
            "langchain-google-vertexai:_2.0.24\n",
            "texttospeech\n",
            "googlesearchapiwrapper\n",
            "langchain-perplexity:_0.1.1\n",
            "langchain-tavily:_0.1.6\n",
            "gcs_file\n",
            "langchain-sema4:_0.2.0\n",
            "langchain-postgres:_0.0.14\n",
            "langchain-google-genai:_2.1.4\n",
            "langchain-cohere:_0.4.4\n",
            "langchain-fireworks:_0.3.0\n",
            "langchain-together:_0.3.0\n",
            "vertexaicheckgroundingwrapper\n",
            "runnableserializable\n",
            "runnable\n",
            "runnableconfig\n",
            "configurablefieldmultioption\n",
            "langchain_google_community.vertex_check_grounding\n",
            "configurablefieldsingleoption\n",
            "configurablefield\n",
            "exponentialjitterparams\n",
            "document\n",
            "gmailcreatedraft\n",
            "sendmessageschema\n",
            "clean_email_body\n",
            "basecallbackhandler\n",
            "searchargsschema\n",
            "gmailgetthread\n",
            "toolexception\n",
            "gmailgetmessage\n",
            "gmailsendmessage\n",
            "gmailsearch\n",
            "build_gmail_service\n",
            "gmailtoolkit\n",
            "toolcall\n",
            "basecallbackmanager\n",
            "build_resource_service\n",
            "createdraftschema\n",
            "resource\n",
            "langchain_google_community.gmail.create_draft\n",
            "gmailloader\n",
            "gmailbasetool\n",
            "get_gmail_credentials\n",
            "getthreadschema\n",
            "cast_proto_type\n",
            "validate_column_in_bq_schema\n",
            "vertexfsvectorstore\n",
            "check_bq_dataset_exists\n",
            "doc_match_filter\n",
            "bigqueryvectorstore\n",
            "langchain_google_community.bq_storage_vectorstores.utils\n",
            "vertexaisearchsummarytool\n",
            "basetool\n",
            "vertexaimultiturnsearchretriever\n",
            "vertexaisearchretriever\n",
            "langchain_google_community.vertex_ai_search\n",
            "vertexairank\n",
            "langchain_google_community.vertex_rank\n",
            "basedocumentcompressor\n",
            "gcsdirectoryloader\n",
            "langchain_google_community.gcs_directory\n",
            "baseloader\n",
            "textsplitter\n",
            "getcalendarsinfo\n",
            "updateeventschema\n",
            "calendarcreateevent\n",
            "langchain_google_community.calendar.get_calendars_info\n",
            "getcurrentdatetime\n",
            "build_calendar_service\n",
            "calendarsearchevents\n",
            "calendarmoveevent\n",
            "currentdatetimeschema\n",
            "build_resouce_service\n",
            "calendarupdateevent\n",
            "createeventschema\n",
            "searcheventsschema\n",
            "deleteeventschema\n",
            "calendartoolkit\n",
            "moveeventschema\n",
            "calendarbasetool\n",
            "calendardeleteevent\n",
            "is_all_day_event\n",
            "docaiparser\n",
            "blob\n",
            "docaiparsingresults\n",
            "operation\n",
            "langchain_google_community.docai\n",
            "texttospeechtool\n",
            "langchain_google_community.texttospeech\n",
            "googlegeocodingtool\n",
            "googlegeocodeinput\n",
            "googlegeocodingapiwrapper\n",
            "langchain_google_community.geocoding\n",
            "fireworks\n",
            "basemessage\n",
            "basecache\n",
            "llm\n",
            "langchain_fireworks.llms\n",
            "embeddings\n",
            "llms\n",
            "chat_models\n",
            "promptvalue\n",
            "bigqueryloader\n",
            "langchain_google_community.bigquery\n",
            "speechtotextloader\n",
            "langchain_google_community.google_speech_to_text\n",
            "gcsfileloader\n",
            "langchain_google_community.gcs_file\n",
            "googleplacesapiwrapper\n",
            "langchain_google_community.places_api\n",
            "googleplacesschema\n",
            "cloudvisionparser\n",
            "cloudvisionloader\n",
            "langchain_google_community.vision\n",
            "googledriveloader\n",
            "langchain_google_community.drive\n",
            "googletranslatetransformer\n",
            "langchain_google_community.translate\n",
            "documentaiwarehouseretriever\n",
            "baseretriever\n",
            "langchain_google_community.documentai_warehouse\n",
            "vectortype\n",
            "langchain_sqlserver.vectorstores\n",
            "overview:_module_code\n",
            "langchain_core.tracers.base\n",
            "basetracer\n",
            "asyncbasetracer\n",
            "langchain_experimental.comprehend_moderation.toxicity\n",
            "comprehendtoxicity\n",
            "langchain_core.utils.json\n",
            "parse_and_check_json_markdown\n",
            "parse_partial_json\n",
            "parse_json_markdown\n",
            "langchain_community.document_loaders.browserbase\n",
            "browserbaseloader\n",
            "langchain_experimental.comprehend_moderation.base_moderation_config\n",
            "moderationpiiconfig\n",
            "moderationtoxicityconfig\n",
            "basemoderationconfig\n",
            "moderationpromptsafetyconfig\n",
            "langchain_mongodb.graphrag.graph\n",
            "langchain_core.runnables.graph_ascii\n",
            "vertexviewer\n",
            "draw_ascii\n",
            "asciicanvas\n",
            "langchain_community.document_compressors.jina_rerank\n",
            "jinarerank\n",
            "langchain_experimental.llm_symbolic_math.base\n",
            "llmsymbolicmathchain\n",
            "langchain_community.agent_toolkits.sql.base\n",
            "create_sql_agent\n",
            "langchain_community.chat_message_histories.mongodb\n",
            "mongodbchatmessagehistory\n",
            "langchain_community.tools.amadeus.flight_search\n",
            "amadeusflightsearch\n",
            "flightsearchschema\n",
            "langchain_experimental.data_anonymizer.deanonymizer_mapping\n",
            "format_duplicated_operator\n",
            "deanonymizermapping\n",
            "create_anonymizer_mapping\n",
            "langchain_community.document_transformers.openai_functions\n",
            "openaimetadatatagger\n",
            "create_metadata_tagger\n",
            "langchain_community.embeddings.dashscope\n",
            "dashscopeembeddings\n",
            "embed_with_retry\n",
            "langchain_community.utilities.google_lens\n",
            "googlelensapiwrapper\n",
            "langchain_core.messages.tool\n",
            "tool_call_chunk\n",
            "tooloutputmixin\n",
            "default_tool_chunk_parser\n",
            "toolmessagechunk\n",
            "invalidtoolcall\n",
            "tool_call\n",
            "default_tool_parser\n",
            "invalid_tool_call\n",
            "toolmessage\n",
            "toolcallchunk\n",
            "langchain_community.document_loaders.parsers.language.code_segmenter\n",
            "codesegmenter\n",
            "langchain_community.chat_models.oci_generative_ai\n",
            "provider\n",
            "metaprovider\n",
            "chatocigenai\n",
            "cohereprovider\n",
            "langchain_community.embeddings.naver\n",
            "clovaxembeddings\n",
            "langchain_core.language_models.chat_models\n",
            "generate_from_stream\n",
            "simplechatmodel\n",
            "basechatmodel\n",
            "agenerate_from_stream\n",
            "langchain_community.callbacks.wandb_callback\n",
            "construct_html_from_prompt_and_generation\n",
            "load_json_to_dict\n",
            "import_wandb\n",
            "analyze_text\n",
            "wandbcallbackhandler\n",
            "langchain_community.utilities.vertexai\n",
            "get_client_info\n",
            "create_retry_decorator\n",
            "init_vertexai\n",
            "load_image_from_gcs\n",
            "raise_vertex_import_error\n",
            "langchain.agents.schema\n",
            "agentscratchpadchatprompttemplate\n",
            "langchain.memory.summary_buffer\n",
            "conversationsummarybuffermemory\n",
            "langchain_community.tools.ainetwork.base\n",
            "ainbasetool\n",
            "operationtype\n",
            "langchain_community.tools.memorize.tool\n",
            "trainablellm\n",
            "memorize\n",
            "langchain_experimental.llms.lmformatenforcer_decoder\n",
            "lmformatenforcer\n",
            "import_lmformatenforcer\n",
            "langchain_community.embeddings.sambanova\n",
            "sambastudioembeddings\n",
            "langchain_google_vertexai.callbacks\n",
            "vertexaicallbackhandler\n",
            "langchain_experimental.text_splitter\n",
            "calculate_cosine_distances\n",
            "combine_sentences\n",
            "semanticchunker\n",
            "langchain_community.llms.chatglm\n",
            "chatglm\n",
            "langchain_community.document_loaders.discord\n",
            "discordchatloader\n",
            "elasticsearch.helpers.vectorstore._async.embedding_service\n",
            "asyncembeddingservice\n",
            "langchain_community.utilities.bing_search\n",
            "bingsearchapiwrapper\n",
            "langchain_unstructured.document_loaders\n",
            "unstructuredloader\n",
            "langchain_community.callbacks.comet_ml_callback\n",
            "cometcallbackhandler\n",
            "import_comet_ml\n",
            "langchain_community.retrievers.arxiv\n",
            "arxivretriever\n",
            "langchain_experimental.data_anonymizer.faker_presidio_mapping\n",
            "get_pseudoanonymizer_mapping\n",
            "langchain_community.retrievers.knn\n",
            "create_index\n",
            "knnretriever\n",
            "langchain_community.document_loaders.parsers.grobid\n",
            "grobidparser\n",
            "serverunavailableexception\n",
            "langchain_community.embeddings.azure_openai\n",
            "azureopenaiembeddings\n",
            "langchain_community.vectorstores.redis.schema\n",
            "redisvectorfield\n",
            "redismodel\n",
            "redisfield\n",
            "numericfieldschema\n",
            "read_schema\n",
            "tagfieldschema\n",
            "flatvectorfield\n",
            "textfieldschema\n",
            "hnswvectorfield\n",
            "redisdistancemetric\n",
            "langchain_community.tools.ainetwork.app\n",
            "appoperationtype\n",
            "appschema\n",
            "ainappops\n",
            "langchain_community.chat_models.fake\n",
            "fakelistchatmodel\n",
            "fakemessageslistchatmodel\n",
            "langchain_community.memory.kg\n",
            "conversationkgmemory\n",
            "langchain_experimental.comprehend_moderation.base_moderation_callbacks\n",
            "basemoderationcallbackhandler\n",
            "langchain_community.tools.office365.base\n",
            "o365basetool\n",
            "langchain.retrievers.merger_retriever\n",
            "mergerretriever\n",
            "langchain_mongodb.docstores\n",
            "langchain.chains.retrieval_qa.base\n",
            "vectordbqa\n",
            "baseretrievalqa\n",
            "retrievalqa\n",
            "langchain_community.graph_vectorstores.extractors.html_link_extractor\n",
            "htmllinkextractor\n",
            "htmlinput\n",
            "langchain_community.retrievers.breebs\n",
            "breebsretriever\n",
            "langchain_upstage.tools.groundedness_check\n",
            "groundednesscheck\n",
            "upstagegroundednesscheckinput\n",
            "upstagegroundednesscheck\n",
            "langchain_community.vectorstores.couchbase\n",
            "couchbasevectorstore\n",
            "langchain_community.callbacks.bedrock_anthropic_callback\n",
            "bedrockanthropictokenusagecallbackhandler\n",
            "langchain_community.vectorstores.redis.filters\n",
            "redisfilterexpression\n",
            "redisfilter\n",
            "redisnum\n",
            "check_operator_misuse\n",
            "redisfilterfield\n",
            "redisfilteroperator\n",
            "redistext\n",
            "redistag\n",
            "langchain_community.llms.yi\n",
            "yillm\n",
            "langchain_community.tools.google_scholar.tool\n",
            "googlescholarqueryrun\n",
            "langchain.storage.encoder_backed\n",
            "encoderbackedstore\n",
            "langchain_community.utilities.cassandra_database\n",
            "cassandradatabase\n",
            "databaseerror\n",
            "table\n",
            "langchain_mongodb.agent_toolkit.tool\n",
            "langchain_community.document_loaders.parsers.images\n",
            "llmimageblobparser\n",
            "baseimageblobparser\n",
            "tesseractblobparser\n",
            "rapidocrblobparser\n",
            "langchain_experimental.cpal.models\n",
            "interventionmodel\n",
            "causalmodel\n",
            "querymodel\n",
            "entitymodel\n",
            "storymodel\n",
            "systemsettingmodel\n",
            "narrativemodel\n",
            "entitysettingmodel\n",
            "resultmodel\n",
            "langchain.memory.simple\n",
            "simplememory\n",
            "langchain_core.output_parsers.list\n",
            "listoutputparser\n",
            "numberedlistoutputparser\n",
            "commaseparatedlistoutputparser\n",
            "droplastn\n",
            "markdownlistoutputparser\n",
            "langchain_community.document_loaders.parsers.language.lua\n",
            "luasegmenter\n",
            "langchain.memory.token_buffer\n",
            "conversationtokenbuffermemory\n",
            "langchain_experimental.video_captioning.services.srt_service\n",
            "srtprocessor\n",
            "langchain.chains.combine_documents.map_reduce\n",
            "mapreducedocumentschain\n",
            "langchain_core.language_models.base\n",
            "baselanguagemodel\n",
            "langsmithparams\n",
            "langchain_community.tools.e2b_data_analysis.tool\n",
            "e2bdataanalysistoolarguments\n",
            "e2bdataanalysistool\n",
            "add_last_line_print\n",
            "uploadedfile\n",
            "langchain_community.tools.slack.get_message\n",
            "slackgetmessage\n",
            "slackgetmessageschema\n",
            "langchain.agents.self_ask_with_search.base\n",
            "selfaskwithsearchagent\n",
            "create_self_ask_with_search_agent\n",
            "selfaskwithsearchchain\n",
            "langchain_community.callbacks.trubrics_callback\n",
            "trubricscallbackhandler\n",
            "langchain_community.tools.requests.tool\n",
            "requestsposttool\n",
            "requestsdeletetool\n",
            "requestspatchtool\n",
            "requestsgettool\n",
            "requestsputtool\n",
            "baserequeststool\n",
            "langchain_postgres.v2.engine\n",
            "pgengine\n",
            "column\n",
            "columndict\n",
            "langchain_core.chat_loaders\n",
            "basechatloader\n",
            "langchain_google_community.gmail.loader\n",
            "langchain.chains.openai_functions.extraction\n",
            "create_extraction_chain\n",
            "create_extraction_chain_pydantic\n",
            "langchain_azure_ai.vectorstores.utils\n",
            "distancestrategy\n",
            "filter_complex_metadata\n",
            "maximal_marginal_relevance\n",
            "langchain_core.embeddings.embeddings\n",
            "langchain_community.llms.human\n",
            "humaninputllm\n",
            "langchain.chains.summarize.chain\n",
            "loadingcallable\n",
            "load_summarize_chain\n",
            "langchain_community.query_constructors.myscale\n",
            "myscaletranslator\n",
            "langchain.agents.output_parsers.react_json_single_input\n",
            "reactjsonsingleinputoutputparser\n",
            "langchain_community.output_parsers.rail_parser\n",
            "guardrailsoutputparser\n",
            "langchain_community.agent_toolkits.multion.toolkit\n",
            "multiontoolkit\n",
            "langchain.chains.openai_functions.base\n",
            "create_openai_fn_chain\n",
            "create_structured_output_chain\n",
            "langchain_postgres.v2.indexes\n",
            "baseindex\n",
            "validate_identifier\n",
            "exactnearestneighbor\n",
            "ivfflatqueryoptions\n",
            "ivfflatindex\n",
            "hnswindex\n",
            "queryoptions\n",
            "hnswqueryoptions\n",
            "strategymixin\n",
            "langchain_community.tools.edenai.audio_speech_to_text\n",
            "speechtotextinput\n",
            "edenaispeechtotexttool\n",
            "langchain_community.agent_toolkits.cogniswitch.toolkit\n",
            "cogniswitchtoolkit\n",
            "langchain_community.chat_models.cohere\n",
            "chatcohere\n",
            "get_role\n",
            "get_cohere_chat_request\n",
            "langchain_experimental.plan_and_execute.planners.base\n",
            "llmplanner\n",
            "baseplanner\n",
            "langchain_community.document_loaders.reddit\n",
            "redditpostsloader\n",
            "langchain_community.tools.audio.huggingface_text_to_speech_inference\n",
            "huggingfacetexttospeechmodelinference\n",
            "langchain_community.llms.edenai\n",
            "edenai\n",
            "langchain_community.storage.redis\n"
          ]
        }
      ],
      "source": [
        "for i in list(documentation.keys())[:500]:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "4f418c0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f418c0a",
        "outputId": "bf44956c-18e4-494c-ce18-365242c858e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "langchain-text-splitters: 0.3.8\n",
            "base\n",
            "TextSplitter\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TextSplitter#\n",
            "\n",
            "\n",
            "class langchain_text_splitters.base.TextSplitter(chunk_size: int = 4000, chunk_overlap: int = 200, length_function: ~typing.Callable[[str], int] = <built-in function len>, keep_separator: bool | ~typing.Literal['start', 'end'] = False, add_start_index: bool = False, strip_whitespace: bool = True)[source]#\n",
            "Interface for splitting text into chunks.\n",
            "Create a new TextSplitter.\n",
            "\n",
            "Parameters:\n",
            "\n",
            "chunk_size (int) ‚Äì Maximum size of chunks to return\n",
            "chunk_overlap (int) ‚Äì Overlap in characters between chunks\n",
            "length_function (Callable[[str], int]) ‚Äì Function that measures the length of given chunks\n",
            "keep_separator (Union[bool, Literal['start', 'end']]) ‚Äì Whether to keep the separator and where to place it\n",
            "in each corresponding chunk (True=‚Äôstart‚Äô)\n",
            "add_start_index (bool) ‚Äì If True, includes chunk‚Äôs start index in metadata\n",
            "strip_whitespace (bool) ‚Äì If True, strips whitespace from the start and end of\n",
            "every document\n",
            "\n",
            "\n",
            "\n",
            "Methods\n",
            "\n",
            "\n",
            "__init__([chunk_size,¬†chunk_overlap,¬†...])\n",
            "Create a new TextSplitter.\n",
            "\n",
            "atransform_documents(documents,¬†**kwargs)\n",
            "Asynchronously transform a list of documents.\n",
            "\n",
            "create_documents(texts[,¬†metadatas])\n",
            "Create documents from a list of texts.\n",
            "\n",
            "from_huggingface_tokenizer(tokenizer,¬†**kwargs)\n",
            "Text splitter that uses HuggingFace tokenizer to count length.\n",
            "\n",
            "from_tiktoken_encoder([encoding_name,¬†...])\n",
            "Text splitter that uses tiktoken encoder to count length.\n",
            "\n",
            "split_documents(documents)\n",
            "Split documents.\n",
            "\n",
            "split_text(text)\n",
            "Split text into multiple components.\n",
            "\n",
            "transform_documents(documents,¬†**kwargs)\n",
            "Transform sequence of documents by splitting them.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "__init__(chunk_size: int = 4000, chunk_overlap: int = 200, length_function: ~typing.Callable[[str], int] = <built-in function len>, keep_separator: bool | ~typing.Literal['start', 'end'] = False, add_start_index: bool = False, strip_whitespace: bool = True) ‚Üí None[source]#\n",
            "Create a new TextSplitter.\n",
            "\n",
            "Parameters:\n",
            "\n",
            "chunk_size (int) ‚Äì Maximum size of chunks to return\n",
            "chunk_overlap (int) ‚Äì Overlap in characters between chunks\n",
            "length_function (Callable[[str], int]) ‚Äì Function that measures the length of given chunks\n",
            "keep_separator (bool | Literal['start', 'end']) ‚Äì Whether to keep the separator and where to place it\n",
            "in each corresponding chunk (True=‚Äôstart‚Äô)\n",
            "add_start_index (bool) ‚Äì If True, includes chunk‚Äôs start index in metadata\n",
            "strip_whitespace (bool) ‚Äì If True, strips whitespace from the start and end of\n",
            "every document\n",
            "\n",
            "\n",
            "Return type:\n",
            "None\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "async atransform_documents(\n",
            "\n",
            "documents: Sequence[Document],\n",
            "**kwargs: Any,\n",
            "\n",
            ") ‚Üí Sequence[Document]#\n",
            "Asynchronously transform a list of documents.\n",
            "\n",
            "Parameters:\n",
            "\n",
            "documents (Sequence[Document]) ‚Äì A sequence of Documents to be transformed.\n",
            "kwargs (Any)\n",
            "\n",
            "\n",
            "Returns:\n",
            "A sequence of transformed Documents.\n",
            "\n",
            "Return type:\n",
            "Sequence[Document]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "create_documents(\n",
            "\n",
            "texts: list[str],\n",
            "metadatas: list[dict[Any, Any]] | None = None,\n",
            "\n",
            ") ‚Üí List[Document][source]#\n",
            "Create documents from a list of texts.\n",
            "\n",
            "Parameters:\n",
            "\n",
            "texts (list[str])\n",
            "metadatas (list[dict[Any, Any]] | None)\n",
            "\n",
            "\n",
            "Return type:\n",
            "List[Document]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "classmethod from_huggingface_tokenizer(\n",
            "\n",
            "tokenizer: Any,\n",
            "**kwargs: Any,\n",
            "\n",
            ") ‚Üí TextSplitter[source]#\n",
            "Text splitter that uses HuggingFace tokenizer to count length.\n",
            "\n",
            "Parameters:\n",
            "\n",
            "tokenizer (Any)\n",
            "kwargs (Any)\n",
            "\n",
            "\n",
            "Return type:\n",
            "TextSplitter\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "classmethod from_tiktoken_encoder(\n",
            "\n",
            "encoding_name: str = 'gpt2',\n",
            "model_name: str | None = None,\n",
            "allowed_special: Literal['all'] | AbstractSet[str] = {},\n",
            "disallowed_special: Literal['all'] | Collection[str] = 'all',\n",
            "**kwargs: Any,\n",
            "\n",
            ") ‚Üí TS[source]#\n",
            "Text splitter that uses tiktoken encoder to count length.\n",
            "\n",
            "Parameters:\n",
            "\n",
            "encoding_name (str)\n",
            "model_name (str | None)\n",
            "allowed_special (Literal['all'] | ~typing.AbstractSet[str])\n",
            "disallowed_special (Literal['all'] | ~typing.Collection[str])\n",
            "kwargs (Any)\n",
            "\n",
            "\n",
            "Return type:\n",
            "TS\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "split_documents(\n",
            "\n",
            "documents: Iterable[Document],\n",
            "\n",
            ") ‚Üí List[Document][source]#\n",
            "Split documents.\n",
            "\n",
            "Parameters:\n",
            "documents (Iterable[Document])\n",
            "\n",
            "Return type:\n",
            "List[Document]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "abstractmethod split_text(text: str) ‚Üí List[str][source]#\n",
            "Split text into multiple components.\n",
            "\n",
            "Parameters:\n",
            "text (str)\n",
            "\n",
            "Return type:\n",
            "List[str]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "transform_documents(\n",
            "\n",
            "documents: Sequence[Document],\n",
            "**kwargs: Any,\n",
            "\n",
            ") ‚Üí Sequence[Document][source]#\n",
            "Transform sequence of documents by splitting them.\n",
            "\n",
            "Parameters:\n",
            "\n",
            "documents (Sequence[Document])\n",
            "kwargs (Any)\n",
            "\n",
            "\n",
            "Return type:\n",
            "Sequence[Document]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " On this page\n",
            "  \n",
            "\n",
            "\n",
            "TextSplitter\n",
            "__init__()\n",
            "atransform_documents()\n",
            "create_documents()\n",
            "from_huggingface_tokenizer()\n",
            "from_tiktoken_encoder()\n",
            "split_documents()\n",
            "split_text()\n",
            "transform_documents()\n"
          ]
        }
      ],
      "source": [
        "print(documentation['textsplitter'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-A1_pIA77RxW",
      "metadata": {
        "id": "-A1_pIA77RxW"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    dataset= open('LangDataset', 'wb')\n",
        "    pickle.dump(documentation, dataset)\n",
        "    dataset.close()\n",
        "\n",
        "except:\n",
        "    print(\"Something went wrong\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qFz5u2DyJgDf",
      "metadata": {
        "id": "qFz5u2DyJgDf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
